{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "from glob import glob\n",
    "from typing import List, Tuple\n",
    "\n",
    "import click\n",
    "import h5py\n",
    "import wget\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "from scipy.ndimage import gaussian_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hdf5(dataset_name: str,\n",
    "                train_size: int,\n",
    "                valid_size: int,\n",
    "                img_size: Tuple[int, int],\n",
    "                in_channels: int=3):\n",
    "    \"\"\"\n",
    "    Create empty training and validation HDF5 files with placeholders\n",
    "    for images and labels (density maps).\n",
    "\n",
    "    Note:\n",
    "    Datasets are saved in [dataset_name]/train.h5 and [dataset_name]/valid.h5.\n",
    "    Existing files will be overwritten.\n",
    "\n",
    "    Args:\n",
    "        dataset_name: used to create a folder for train.h5 and valid.h5\n",
    "        train_size: no. of training samples\n",
    "        valid_size: no. of validation samples\n",
    "        img_size: (width, height) of a single image / density map\n",
    "        in_channels: no. of channels of an input image\n",
    "\n",
    "    Returns:\n",
    "        A tuple of pointers to training and validation HDF5 files.\n",
    "    \"\"\"\n",
    "    # create output folder if it does not exist\n",
    "    os.makedirs(dataset_name, exist_ok=True)\n",
    "\n",
    "    # create HDF5 files: [dataset_name]/(train | valid).h5\n",
    "    train_h5 = h5py.File(os.path.join(dataset_name, 'train.h5'), 'w')\n",
    "    valid_h5 = h5py.File(os.path.join(dataset_name, 'valid.h5'), 'w')\n",
    "\n",
    "    # add two HDF5 datasets (images and labels) for each HDF5 file\n",
    "    for h5, size in ((train_h5, train_size), (valid_h5, valid_size)):\n",
    "        h5.create_dataset('images', (size, in_channels, *img_size))\n",
    "        h5.create_dataset('labels', (size, 1, *img_size))\n",
    "\n",
    "    return train_h5, valid_h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mall_data():\n",
    "    \"\"\"Generate HDF5 files for mall dataset.\"\"\"\n",
    "    # download and extract dataset\n",
    "    # get_and_unzip(\n",
    "    #     'http://personal.ie.cuhk.edu.hk/~ccloy/files/datasets/mall_dataset.zip'\n",
    "    # )\n",
    "    # create training and validation HDF5 files\n",
    "    train_h5, valid_h5 = create_hdf5('mall',\n",
    "                                     train_size=1500,\n",
    "                                     valid_size=500,\n",
    "                                     img_size=(480, 640),\n",
    "                                     in_channels=3)\n",
    "\n",
    "    # load labels infomation from provided MATLAB file\n",
    "    # it is a numpy array with (x, y) objects position for subsequent frames\n",
    "    labels = loadmat('mall_dataset/mall_gt.mat')['frame'][0]\n",
    "\n",
    "    def fill_h5(h5, labels, init_frame=0):\n",
    "        \"\"\"\n",
    "        Save images and labels in given HDF5 file.\n",
    "\n",
    "        Args:\n",
    "            h5: HDF5 file\n",
    "            labels: the list of labels\n",
    "            init_frame: the first frame in given list of labels\n",
    "        \"\"\"\n",
    "        for i, label in enumerate(labels, init_frame):\n",
    "            # path to the next frame (filename convention: seq_XXXXXX.jpg)\n",
    "            img_path = f\"mall_dataset/frames/seq_{str(i+1).zfill(6)}.jpg\"\n",
    "\n",
    "            # get an image as numpy array\n",
    "            image = np.array(Image.open(img_path), dtype=np.float32) / 255\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "\n",
    "            # generate a density map by applying a Gaussian filter\n",
    "            label = generate_label(label[0][0][0], image.shape[1:])\n",
    "\n",
    "            # save data to HDF5 file\n",
    "            h5['images'][i - init_frame] = image\n",
    "            h5['labels'][i - init_frame, 0] = label\n",
    "\n",
    "    # use first 1500 frames for training and the last 500 for validation\n",
    "    fill_h5(train_h5, labels[:1500])\n",
    "    fill_h5(valid_h5, labels[1500:], 1500)\n",
    "\n",
    "    # close HDF5 file\n",
    "    train_h5.close()\n",
    "    valid_h5.close()\n",
    "\n",
    "    # cleanup\n",
    "    shutil.rmtree('mall_dataset')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b365f9a903530fb1c7fc8e3250adccc9ef58f552e7d6dbebb5b0fc5f4f0654e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
